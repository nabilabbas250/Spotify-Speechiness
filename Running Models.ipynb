{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /Users/flatironschool/anaconda3/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/flatironschool/anaconda3/lib/python3.7/site-packages (from imblearn) (0.5.0)\n",
      "Requirement already satisfied: scipy>=0.17 in /Users/flatironschool/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /Users/flatironschool/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/flatironschool/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.13.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /Users/flatironschool/anaconda3/lib/python3.7/site-packages (from imbalanced-learn->imblearn) (0.21.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('df2_info.csv')\n",
    "df2 = df2.set_index('id')\n",
    "df2.drop(columns = 'SPEECH_musical', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>...</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "      <th>mode_0</th>\n",
       "      <th>mode_1</th>\n",
       "      <th>time_signature_0</th>\n",
       "      <th>time_signature_1</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "      <th>SPEECH_speechy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30oTS7bm0aH3p7lqjEIu8q</th>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.877</td>\n",
       "      <td>216596</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>-5.885</td>\n",
       "      <td>0.271</td>\n",
       "      <td>95.224</td>\n",
       "      <td>0.754</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2g8HN35AnVGIk7B8yMucww</th>\n",
       "      <td>0.4320</td>\n",
       "      <td>0.778</td>\n",
       "      <td>252747</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>-7.220</td>\n",
       "      <td>0.274</td>\n",
       "      <td>84.487</td>\n",
       "      <td>0.758</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33ZXjLCpiINn8eQIDYEPTD</th>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.763</td>\n",
       "      <td>325507</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>-6.472</td>\n",
       "      <td>0.229</td>\n",
       "      <td>93.857</td>\n",
       "      <td>0.504</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2qOm7ukLyHUXWyR4ZWLwxA</th>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.796</td>\n",
       "      <td>260000</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>-5.409</td>\n",
       "      <td>0.126</td>\n",
       "      <td>82.384</td>\n",
       "      <td>0.802</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119c93MHjrDLJTApCVGpvx</th>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.479</td>\n",
       "      <td>252187</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>-10.551</td>\n",
       "      <td>0.373</td>\n",
       "      <td>180.985</td>\n",
       "      <td>0.576</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        acousticness  danceability  duration_ms  energy  \\\n",
       "id                                                                        \n",
       "30oTS7bm0aH3p7lqjEIu8q        0.0253         0.877       216596   0.740   \n",
       "2g8HN35AnVGIk7B8yMucww        0.4320         0.778       252747   0.578   \n",
       "33ZXjLCpiINn8eQIDYEPTD        0.0146         0.763       325507   0.786   \n",
       "2qOm7ukLyHUXWyR4ZWLwxA        0.3210         0.796       260000   0.748   \n",
       "119c93MHjrDLJTApCVGpvx        0.5700         0.479       252187   0.549   \n",
       "\n",
       "                        instrumentalness  liveness  loudness  speechiness  \\\n",
       "id                                                                          \n",
       "30oTS7bm0aH3p7lqjEIu8q          0.000003    0.2860    -5.885        0.271   \n",
       "2g8HN35AnVGIk7B8yMucww          0.000000    0.1380    -7.220        0.274   \n",
       "33ZXjLCpiINn8eQIDYEPTD          0.011400    0.0817    -6.472        0.229   \n",
       "2qOm7ukLyHUXWyR4ZWLwxA          0.000049    0.2170    -5.409        0.126   \n",
       "119c93MHjrDLJTApCVGpvx          0.023900    0.1270   -10.551        0.373   \n",
       "\n",
       "                          tempo  valence  ...  key_10  key_11  mode_0  mode_1  \\\n",
       "id                                        ...                                   \n",
       "30oTS7bm0aH3p7lqjEIu8q   95.224    0.754  ...       0       0       0       1   \n",
       "2g8HN35AnVGIk7B8yMucww   84.487    0.758  ...       0       0       1       0   \n",
       "33ZXjLCpiINn8eQIDYEPTD   93.857    0.504  ...       1       0       1       0   \n",
       "2qOm7ukLyHUXWyR4ZWLwxA   82.384    0.802  ...       0       0       1       0   \n",
       "119c93MHjrDLJTApCVGpvx  180.985    0.576  ...       0       1       1       0   \n",
       "\n",
       "                        time_signature_0  time_signature_1  time_signature_3  \\\n",
       "id                                                                             \n",
       "30oTS7bm0aH3p7lqjEIu8q                 0                 0                 0   \n",
       "2g8HN35AnVGIk7B8yMucww                 0                 0                 0   \n",
       "33ZXjLCpiINn8eQIDYEPTD                 0                 0                 0   \n",
       "2qOm7ukLyHUXWyR4ZWLwxA                 0                 0                 0   \n",
       "119c93MHjrDLJTApCVGpvx                 0                 0                 0   \n",
       "\n",
       "                        time_signature_4  time_signature_5  SPEECH_speechy  \n",
       "id                                                                          \n",
       "30oTS7bm0aH3p7lqjEIu8q                 1                 0               0  \n",
       "2g8HN35AnVGIk7B8yMucww                 1                 0               0  \n",
       "33ZXjLCpiINn8eQIDYEPTD                 1                 0               0  \n",
       "2qOm7ukLyHUXWyR4ZWLwxA                 1                 0               0  \n",
       "119c93MHjrDLJTApCVGpvx                 1                 0               1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smote\n",
    "\n",
    "1) import smote\n",
    "\n",
    "2) train test split\n",
    "\n",
    "3) create smote instance\n",
    "\n",
    "4) resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(columns = ['speechiness', 'SPEECH_speechy'])\n",
    "df4 = df2['SPEECH_speechy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imbalance Preview:\n",
      "0    1077\n",
      "1     332\n",
      "Name: SPEECH_speechy, dtype: int64\n",
      "0    0.764372\n",
      "1    0.235628\n",
      "Name: SPEECH_speechy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X = df3\n",
    "y = df4\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n",
    "\n",
    "print('Imbalance Preview:')\n",
    "print(y.value_counts())\n",
    "print(y.value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1077\n",
      "1     332\n",
      "Name: SPEECH_speechy, dtype: int64\n",
      "1    809\n",
      "0    809\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts())\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_sample(X_train, y_train)\n",
    "\n",
    "print(pd.Series(y_train_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>key_0</th>\n",
       "      <th>...</th>\n",
       "      <th>key_9</th>\n",
       "      <th>key_10</th>\n",
       "      <th>key_11</th>\n",
       "      <th>mode_0</th>\n",
       "      <th>mode_1</th>\n",
       "      <th>time_signature_0</th>\n",
       "      <th>time_signature_1</th>\n",
       "      <th>time_signature_3</th>\n",
       "      <th>time_signature_4</th>\n",
       "      <th>time_signature_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.647728</td>\n",
       "      <td>1.302019</td>\n",
       "      <td>-1.502658</td>\n",
       "      <td>-2.613450</td>\n",
       "      <td>5.471883</td>\n",
       "      <td>-0.695585</td>\n",
       "      <td>-1.084610</td>\n",
       "      <td>0.836017</td>\n",
       "      <td>0.382281</td>\n",
       "      <td>-0.294046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306423</td>\n",
       "      <td>-0.287285</td>\n",
       "      <td>-0.338748</td>\n",
       "      <td>1.153202</td>\n",
       "      <td>-1.153202</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>-0.078873</td>\n",
       "      <td>-0.152212</td>\n",
       "      <td>0.260276</td>\n",
       "      <td>-0.190088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.769829</td>\n",
       "      <td>-1.183765</td>\n",
       "      <td>-0.189597</td>\n",
       "      <td>-0.131531</td>\n",
       "      <td>-0.218458</td>\n",
       "      <td>-0.310442</td>\n",
       "      <td>-0.224571</td>\n",
       "      <td>-0.725265</td>\n",
       "      <td>-0.759105</td>\n",
       "      <td>-0.294046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306423</td>\n",
       "      <td>-0.287285</td>\n",
       "      <td>-0.338748</td>\n",
       "      <td>1.153202</td>\n",
       "      <td>-1.153202</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>-0.078873</td>\n",
       "      <td>-0.152212</td>\n",
       "      <td>0.260276</td>\n",
       "      <td>-0.190088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.976837</td>\n",
       "      <td>0.540608</td>\n",
       "      <td>-0.475223</td>\n",
       "      <td>0.249821</td>\n",
       "      <td>-0.218329</td>\n",
       "      <td>-0.793796</td>\n",
       "      <td>0.073796</td>\n",
       "      <td>1.108972</td>\n",
       "      <td>-0.870214</td>\n",
       "      <td>-0.294046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306423</td>\n",
       "      <td>-0.287285</td>\n",
       "      <td>-0.338748</td>\n",
       "      <td>1.153202</td>\n",
       "      <td>-1.153202</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>-0.078873</td>\n",
       "      <td>-0.152212</td>\n",
       "      <td>0.260276</td>\n",
       "      <td>-0.190088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.958370</td>\n",
       "      <td>0.995962</td>\n",
       "      <td>-0.666188</td>\n",
       "      <td>0.993771</td>\n",
       "      <td>-0.194325</td>\n",
       "      <td>-0.503014</td>\n",
       "      <td>1.225047</td>\n",
       "      <td>-0.575387</td>\n",
       "      <td>1.346904</td>\n",
       "      <td>-0.294046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306423</td>\n",
       "      <td>-0.287285</td>\n",
       "      <td>3.430363</td>\n",
       "      <td>-0.972663</td>\n",
       "      <td>0.972663</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>-0.078873</td>\n",
       "      <td>-0.152212</td>\n",
       "      <td>0.260276</td>\n",
       "      <td>-0.190088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.798639</td>\n",
       "      <td>-0.452212</td>\n",
       "      <td>-1.291790</td>\n",
       "      <td>0.149794</td>\n",
       "      <td>-0.218458</td>\n",
       "      <td>-0.663490</td>\n",
       "      <td>1.710161</td>\n",
       "      <td>-1.228949</td>\n",
       "      <td>-0.738904</td>\n",
       "      <td>-0.294046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306423</td>\n",
       "      <td>3.749740</td>\n",
       "      <td>-0.338748</td>\n",
       "      <td>1.153202</td>\n",
       "      <td>-1.153202</td>\n",
       "      <td>-0.024868</td>\n",
       "      <td>-0.078873</td>\n",
       "      <td>-0.152212</td>\n",
       "      <td>0.260276</td>\n",
       "      <td>-0.190088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms    energy  instrumentalness  \\\n",
       "0      2.647728      1.302019    -1.502658 -2.613450          5.471883   \n",
       "1     -0.769829     -1.183765    -0.189597 -0.131531         -0.218458   \n",
       "2     -0.976837      0.540608    -0.475223  0.249821         -0.218329   \n",
       "3     -0.958370      0.995962    -0.666188  0.993771         -0.194325   \n",
       "4     -0.798639     -0.452212    -1.291790  0.149794         -0.218458   \n",
       "\n",
       "   liveness  loudness     tempo   valence     key_0  ...     key_9    key_10  \\\n",
       "0 -0.695585 -1.084610  0.836017  0.382281 -0.294046  ... -0.306423 -0.287285   \n",
       "1 -0.310442 -0.224571 -0.725265 -0.759105 -0.294046  ... -0.306423 -0.287285   \n",
       "2 -0.793796  0.073796  1.108972 -0.870214 -0.294046  ... -0.306423 -0.287285   \n",
       "3 -0.503014  1.225047 -0.575387  1.346904 -0.294046  ... -0.306423 -0.287285   \n",
       "4 -0.663490  1.710161 -1.228949 -0.738904 -0.294046  ... -0.306423  3.749740   \n",
       "\n",
       "     key_11    mode_0    mode_1  time_signature_0  time_signature_1  \\\n",
       "0 -0.338748  1.153202 -1.153202         -0.024868         -0.078873   \n",
       "1 -0.338748  1.153202 -1.153202         -0.024868         -0.078873   \n",
       "2 -0.338748  1.153202 -1.153202         -0.024868         -0.078873   \n",
       "3  3.430363 -0.972663  0.972663         -0.024868         -0.078873   \n",
       "4 -0.338748  1.153202 -1.153202         -0.024868         -0.078873   \n",
       "\n",
       "   time_signature_3  time_signature_4  time_signature_5  \n",
       "0         -0.152212          0.260276         -0.190088  \n",
       "1         -0.152212          0.260276         -0.190088  \n",
       "2         -0.152212          0.260276         -0.190088  \n",
       "3         -0.152212          0.260276         -0.190088  \n",
       "4         -0.152212          0.260276         -0.190088  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instantiate the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Scaled train data, followed by scaled test data as arrays\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#convert trained data array to dataframe with columns from df1\n",
    "scaled_df_train = pd.DataFrame(X_train_scaled, columns = df3.columns)\n",
    "scaled_df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Classifier to Beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.0\n",
      "Recall Score: 0.0\n",
      "Accuracy Score: 0.7592067988668555\n",
      "F1 Score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/flatironschool/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# import models / tools\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#function to print metrics\n",
    "def print_metrics(test, preds):\n",
    "    print(\"Precision Score: {}\".format(precision_score(test, preds)))\n",
    "    print(\"Recall Score: {}\".format(recall_score(test, preds)))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(test, preds)))\n",
    "    print(\"F1 Score: {}\".format(f1_score(test, preds)))\n",
    "\n",
    "# Fitting and training the dummy\n",
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "# Dummy predictions\n",
    "dum_pred = dummy.predict(X_test_scaled)\n",
    "\n",
    "#Printing out results\n",
    "print_metrics(y_test, dum_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import knn\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "# instantiate knn\n",
    "clf = KNeighborsClassifier(n_neighbors= 1, p= 1, weights= 'uniform')\n",
    "\n",
    "# fit classifier into your model\n",
    "clf.fit(X_train_scaled, y_train_resampled)\n",
    "### When I did clf.fit over here, I created the model and trained it for future iterations\n",
    "\n",
    "#output is an array of the predicted types of glass\n",
    "test_preds = clf.predict(X_test_scaled) \n",
    "\n",
    "#clf is my where my model exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.5429370629370629\n",
      "Recall Score: 0.5404302019315188\n",
      "Accuracy Score: 0.6742209631728046\n",
      "F1 Score: 0.5413460777999977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "def print_metrics(labels, preds):\n",
    "    print(\"Precision Score: {}\".format(precision_score(labels, preds, average = 'macro')))\n",
    "    print(\"Recall Score: {}\".format(recall_score(labels, preds, average = 'macro')))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(labels, preds)))\n",
    "    print(\"F1 Score: {}\".format(f1_score(labels, preds, average = 'macro')))\n",
    "    \n",
    "print_metrics(y_test, test_preds) # comparing my test vs predictable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set new model equal to your grid search.  you're reinstatiated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  KNN Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_params = {'n_neighbors': list(range(1,15)), \n",
    "               'weights': ['uniform', 'distance'],\n",
    "               'p' :[1,2]}\n",
    "\n",
    "gs = GridSearchCV(clf, grid_params, cv=10)\n",
    "\n",
    "gs_results = gs.fit(X_train_scaled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=1,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn = gs_results.best_estimator_\n",
    "clf_knn.fit(X_train_scaled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.5404302019315188\n",
      "Recall Score: 0.5429370629370629\n",
      "Accuracy Score: 0.6742209631728046\n",
      "F1 Score: 0.5413460777999977\n"
     ]
    }
   ],
   "source": [
    "gs_knn_test = clf_knn.predict(X_test_scaled)\n",
    "\n",
    "print_metrics(gs_knn_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new model using the better paramater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=1,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_knn = gs.best_estimator_\n",
    "clf_knn.fit(X_train_scaled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1, 'p': 1, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.857849196538937"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COME BACK AND REINSTANTIATE THE THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.5440268700072621\n",
      "Recall Score: 0.5425812115891132\n",
      "Accuracy Score: 0.6713881019830028\n",
      "F1 Score: 0.5431950022311468\n"
     ]
    }
   ],
   "source": [
    "#import model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#instantiate model\n",
    "clf2 = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "#fit the model\n",
    "clf2 = logreg.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "#test your test data on the model\n",
    "test_preds2 = clf2.predict(X_test_scaled)\n",
    "\n",
    "#check your performance\n",
    "print_metrics(y_test, test_preds) # comparing my test vs predictable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the model on the train and test data again and see how well it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = clf2.predict(X_test_scaled)\n",
    "y_hat_train = clf2.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model predicted 67% of training data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1096\n",
      "1     522\n",
      "dtype: int64\n",
      "0    0.677379\n",
      "1    0.322621\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "residuals = np.abs(y_train_resampled - y_hat_train)\n",
    "print(pd.Series(residuals).value_counts())\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model predicted 62% of the testing data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    219\n",
      "1    134\n",
      "Name: SPEECH_speechy, dtype: int64\n",
      "0    0.620397\n",
      "1    0.379603\n",
      "Name: SPEECH_speechy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "residuals = np.abs(y_test - y_hat_test)\n",
    "print(pd.Series(residuals).value_counts())\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X_train_scaled\n",
    "### X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost, Random Forest, Decision Tree, AdaBoost, SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.5710570347737524\n",
      "Recall Score: 0.5857550482879719\n",
      "Accuracy Score: 0.6515580736543909\n",
      "F1 Score: 0.5722476725284469\n"
     ]
    }
   ],
   "source": [
    "#instatiate the Decision Tree Classifier\n",
    "clf3 = DecisionTreeClassifier()\n",
    "\n",
    "#Fit the model to the scaled training data\n",
    "clf3.fit(X_train_scaled, y_train_resampled) \n",
    "\n",
    "#testing test data on model\n",
    "test_preds3 = clf3.predict(X_test_scaled)\n",
    "\n",
    "print_metrics(y_test, test_preds3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gridsearch to determine optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.6240263418779209\n",
      "Recall Score: 0.5768876207199298\n",
      "Accuracy Score: 0.7478753541076487\n",
      "F1 Score: 0.5829140391636243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flatironschool/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf4 = RandomForestClassifier()\n",
    "clf4.fit(X_train_scaled, y_train_resampled)\n",
    "test_preds4 = clf4.predict(X_test_scaled)\n",
    "\n",
    "print_metrics(y_test, test_preds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import randomized search\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "#state parameters in a dictionary\n",
    "param_distrib = {'n_estimators': randint(10, 1000),\n",
    "                 \"max_depth\": randint(1, 50),\n",
    "              \"max_features\": randint(1, 16),\n",
    "                 \"min_samples_leaf\": randint(2, 1000),\n",
    "              \"min_samples_split\": randint(2, 1000),\n",
    "                 \n",
    "                }\n",
    "\n",
    "# INSTANCE\n",
    "clf_RF = RandomizedSearchCV(RandomForestClassifier(), param_distrib, n_iter=500, cv =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rs = RandomizedSearchCV(RandomForestClassifier(), param_distrib, n_iter=500, cv =3)\n",
    "\n",
    "#rs_results = gs.fit(X_train_scaled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I WAS DUMB AND SHOULD HAVE FITTED IT W/O RS (i.e. just clf_RF), RS IS MY MODEL NOW\n",
    "\n",
    "rs = clf_RF.fit(X_train_scaled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=46, max_features=5, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=23, min_samples_split=34,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=178,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.6087357330992098\n",
      "Recall Score: 0.6447691408533022\n",
      "Accuracy Score: 0.7535410764872521\n",
      "F1 Score: 0.618539542162988\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "clf_rf_actual = rs.best_estimator_\n",
    "clf_rf_actual.fit(X_train_scaled, y_train_resampled)\n",
    "rs_test_preds = clf_rf_actual.predict(X_test_scaled)\n",
    "print_metrics(rs_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, x_train, n=30):\n",
    "    # extract and sort the feature importance\n",
    "    features = model.feature_importances_\n",
    "    feature_names = x_train.columns.values\n",
    "    \n",
    "    # combine the features importance and column names into a matrix and sort them\n",
    "    feature_matrix = np.array([features, feature_names])\n",
    "    feature_matrix = feature_matrix.transpose()\n",
    "    feature_matrix.sort(0)\n",
    "    \n",
    "    # divide the column names and feature importance\n",
    "    sorted_feat = feature_matrix[:, 0]\n",
    "    sorted_columns = feature_matrix[:, 1]\n",
    "    \n",
    "     # plot the features\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    try:\n",
    "        plt.barh(sorted_columns[-n:], sorted_feat[-n:], align='center')\n",
    "    \n",
    "    except:\n",
    "        # if n features is greater than the amount that actually exists\n",
    "        n = len(sorted_feat)\n",
    "        plt.barh(sorted_columns[-n:], sorted_feat[-n:], align='center')\n",
    "        \n",
    "    plt.yticks(sorted_columns[-n:], sorted_columns[-n:])\n",
    "    plt.xlabel(\"Feature Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    #Pseudocode/Outline:\n",
    "    #Print the confusion matrix (optional)\n",
    "    #Create the basic matrix.\n",
    "    #Add title and Axis Labels\n",
    "    #Add appropriate Axis Scales\n",
    "    #Add Labels to Each Cell\n",
    "    #Add a Side Bar Legend Showing Colors\n",
    "    \n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models to still run:\n",
    "\n",
    "XG boost, adaboost, svm,\n",
    "\n",
    "run grid search "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
